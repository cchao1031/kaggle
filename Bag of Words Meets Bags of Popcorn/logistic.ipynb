{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_train = pd.read_csv('labeledTrainData.tsv', sep='\\t', quoting=3)\n",
    "data_test = pd.read_csv('testData.tsv', sep='\\t', quoting=3)\n",
    "\n",
    "y_train = data_train[\"sentiment\"]  \n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing movie reviews...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file F:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review train 5000 of 25000\n",
      "\n",
      "Review train 10000 of 25000\n",
      "\n",
      "Review train 15000 of 25000\n",
      "\n",
      "Review train 20000 of 25000\n",
      "\n",
      "Review train 25000 of 25000\n",
      "\n",
      "Review test 5000 of 25000\n",
      "\n",
      "Review test 10000 of 25000\n",
      "\n",
      "Review test 15000 of 25000\n",
      "\n",
      "Review test 20000 of 25000\n",
      "\n",
      "Review test 25000 of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def review_to_words(review_raw, stop_words):\n",
    "    review_text = BeautifulSoup(review_raw).get_text()\n",
    "        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    \n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    meaningful_words = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    return(\" \".join(meaningful_words))\n",
    "\n",
    "\n",
    "print \"Cleaning and parsing movie reviews...\\n\"      \n",
    "feature_train = []\n",
    "m_train = len(data_train.review)\n",
    "for i in xrange(m_train):\n",
    "    if( (i+1)%5000 == 0 ):\n",
    "        print \"Review train %d of %d\\n\" % ( i+1, m_train )    \n",
    "    feature_train.append( review_to_words(data_train.review[i], stops))\n",
    "feature_test = []\n",
    "m_test = len(data_test.review)\n",
    "for i in xrange(m_test):\n",
    "    if( (i+1)%5000 == 0 ):\n",
    "        print \"Review test %d of %d\\n\" % ( i+1, m_test )    \n",
    "    feature_test.append( review_to_words(data_test.review[i], stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('tfidf', TfidfVectorizer), ('lr', LogisticRegression)])\n",
    "paramaters = {\n",
    "    'tfidf__'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizing... \n"
     ]
    }
   ],
   "source": [
    "print 'vectorizing... ', \n",
    "vectorizer = TfidfVectorizer(analyzer='word', max_features=5000)\n",
    "feature_all = feature_train + feature_test\n",
    "vectorizer_fit = vectorizer.fit(feature_all)\n",
    "X_train = vectorizer_fit.transform(feature_train).toarray()\n",
    "X_test = vectorizer_fit.transform(feature_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Fold CV Score:  0.929038592\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, \n",
    "                         C=1, fit_intercept=True, intercept_scaling=1.0, \n",
    "                         class_weight=None, random_state=1031, n_jobs=-1)\n",
    "print \"20 Fold CV Score: \", np.mean(cross_validation.cross_val_score(model, X_train, y_train, cv=20, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain on all training data, predicting test labels...\n",
      "\n",
      "Wrote results to Bag_of_Words_model.csv\n"
     ]
    }
   ],
   "source": [
    "print \"Retrain on all training data, predicting test labels...\\n\"\n",
    "model.fit(X_train, y_train)\n",
    "result = model.predict_proba(X_test)[:,1]\n",
    "output = pd.DataFrame( data={\"id\": data_test.id, \"sentiment\": result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv('logistic.csv', index=False, quoting=3)\n",
    "print \"Wrote results to logistic.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
